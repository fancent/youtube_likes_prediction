{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "youtube_ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_mWxxSOPup0"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz\n",
        "!tar -xvf spark-3.0.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYBJTUHnPKK1"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import *\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark import SparkConf\n",
        "from pyspark.context import SparkContext\n",
        "sc = SparkContext.getOrCreate(SparkConf())\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import pyspark.sql.functions as f\n",
        "import pyspark.sql.types as types\n",
        "from pyspark import sql\n",
        "from pyspark.sql.functions import unix_timestamp\n",
        "from time import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbbBYJcjPxcG"
      },
      "source": [
        "spark = sql.SparkSession.builder \\\n",
        "    .master(\"local\") \\\n",
        "    .appName(\"ML Youtube\") \\\n",
        "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NWqMKmO_YDT",
        "outputId": "e588a31a-43cf-4ec0-d525-454d9fc2355a"
      },
      "source": [
        "from urllib.request import urllib\r\n",
        "General_url = \"https://billypoon.blob.core.windows.net/project/data/processed\"\r\n",
        "\r\n",
        "CA_url = General_url+\"/CA.csv\"\r\n",
        "IN_url = General_url+\"/IN.csv\"\r\n",
        "GB_url = General_url+\"/GB.csv\"\r\n",
        "US_url = General_url+\"/US.csv\"\r\n",
        "DE_url = General_url+\"/DE.csv\"\r\n",
        "FR_url = General_url+\"/FR.csv\"\r\n",
        "\r\n",
        "CA_file = \"CA.csv\"\r\n",
        "IN_file = \"IN.csv\"\r\n",
        "GB_file = \"GB.csv\"\r\n",
        "US_file = \"US.csv\"\r\n",
        "DE_file = \"DE.csv\"\r\n",
        "FR_file = \"FR.csv\"\r\n",
        "\r\n",
        "urllib.request.urlretrieve(CA_url, CA_file)\r\n",
        "urllib.request.urlretrieve(IN_url, IN_file)\r\n",
        "urllib.request.urlretrieve(GB_url, GB_file)\r\n",
        "urllib.request.urlretrieve(US_url, US_file)\r\n",
        "urllib.request.urlretrieve(DE_url, DE_file)\r\n",
        "urllib.request.urlretrieve(FR_url, FR_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('FR.csv', <http.client.HTTPMessage at 0x7f030dfce208>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqqU8klDBbBU"
      },
      "source": [
        "custom_schema = StructType([\r\n",
        "    StructField('video_id', StringType(), False),\r\n",
        "    StructField('title', StringType(), False),\r\n",
        "    StructField('category_id', IntegerType(), False),\r\n",
        "    StructField('tags', StringType(), False),\r\n",
        "    StructField('views', IntegerType(), False),\r\n",
        "    StructField('likes', IntegerType(), False),\r\n",
        "    StructField('dislikes', IntegerType(), False),\r\n",
        "    StructField('comment_count', IntegerType(), False),\r\n",
        "    StructField('description', StringType(), False),\r\n",
        "    StructField('category_title', StringType(), False),\r\n",
        "    StructField('region', StringType(), False),\r\n",
        "    StructField('lang', StringType(), False)\r\n",
        "])\r\n",
        "\r\n",
        "df_IN = spark.read.csv(IN_file, header=True, schema=custom_schema, multiLine=True)\r\n",
        "df_GB = spark.read.csv(GB_file, header=True, schema=custom_schema, multiLine=True)\r\n",
        "df_US = spark.read.csv(US_file, header=True, schema=custom_schema, multiLine=True)\r\n",
        "df_CA = spark.read.csv(CA_file, header=True, schema=custom_schema, multiLine=True)\r\n",
        "df_DE = spark.read.csv(DE_file, header=True, schema=custom_schema, multiLine=True)\r\n",
        "df_FR = spark.read.csv(FR_file, header=True, schema=custom_schema, multiLine=True)\r\n",
        "df_ALL = df_IN.union(df_GB).union(df_US).union(df_CA).union(df_DE).union(df_FR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsIvCVMMSCPo"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCOKwM5qPKMr"
      },
      "source": [
        "def viewsRange(x):\n",
        "    if x <= 10000:\n",
        "        return 0.\n",
        "    elif x <= 50000:\n",
        "        return 1.\n",
        "    elif x <= 100000:\n",
        "        return 2.\n",
        "    elif x <= 250000:\n",
        "        return 3.\n",
        "    elif x <= 500000:\n",
        "        return 4.\n",
        "    elif x <= 750000:\n",
        "        return 5.\n",
        "    elif x <= 1000000:\n",
        "        return 6.\n",
        "    elif x <= 1500000:\n",
        "        return 7.\n",
        "    elif x <= 2500000:\n",
        "        return 8.\n",
        "    else:\n",
        "        return 9.\n",
        "\n",
        "viewsRangeUDF = udf(lambda x: viewsRange(x), FloatType())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZvEy2DlWCGH"
      },
      "source": [
        "df_ALL = df_ALL.withColumn('viewlabel', viewsRangeUDF(df_ALL['views']))\n",
        "df_ALL = df_ALL.withColumn('log_views', f.log10(df_ALL.views+1))\n",
        "df_ALL = df_ALL.withColumn('log_likes', f.log10(df_ALL.likes+1))\n",
        "df_ALL = df_ALL.withColumn('log_dislikes', f.log10(df_ALL.dislikes+1))\n",
        "df_ALL = df_ALL.withColumn('log_comment_count', f.log10(df_ALL.comment_count+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qosDBF03q8fK"
      },
      "source": [
        "# Views Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXr2JX7hq1Nv"
      },
      "source": [
        "### Vectorize Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0H5MnULPKMz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "269e182c-0b44-4f67-c8da-d7e004bbbb0f"
      },
      "source": [
        "viewData = df_ALL\n",
        "required_features = [\n",
        "    'category_id',\n",
        "    'log_likes',     \n",
        "    'log_dislikes',\n",
        "    'log_comment_count'\n",
        "]\n",
        "assembler = VectorAssembler(inputCols=required_features, outputCol='features')\n",
        "start_time = time()\n",
        "data_feature = assembler.transform(viewData)\n",
        "data_feature = data_feature.select(col('viewlabel').alias('label'),data_feature['features'])\n",
        "print(f\"Time elapsed for featurizing data: {time()-start_time:.2f}s\")\n",
        "del start_time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time elapsed for featurizing data: 0.33s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYKn41WHPKM4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc18910a-6d5c-4420-aa2c-65f24c897c5c"
      },
      "source": [
        "## Data_split\n",
        "data_train, data_test = data_feature.randomSplit([0.8, 0.2])\n",
        "data_train.cache()\n",
        "data_test.cache()\n",
        "start_time = time()\n",
        "data_train.collect()\n",
        "data_test.collect()\n",
        "print(f\"Time elapsed for collecting data: {time()-start_time:.2f}s\")\n",
        "del start_time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time elapsed for collecting data: 22.57s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWzGs7E7zPEf"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PnyEXlukVs0"
      },
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, GBTClassifier, MultilayerPerceptronClassifier, LinearSVC, OneVsRest, NaiveBayes, FMClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.regression import DecisionTreeRegressor, GBTRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaY_W7IBkW5-"
      },
      "source": [
        "lr1 = LogisticRegression(maxIter=10, tol=1E-6, fitIntercept=True, labelCol='label', featuresCol='features')\n",
        "lr2 = LogisticRegression(maxIter=10, tol=1E-6, fitIntercept=True, labelCol='label', featuresCol='features')\n",
        "dt3 = DecisionTreeRegressor(labelCol='label', featuresCol='features')\n",
        "rf4 = RandomForestClassifier(labelCol='label', featuresCol='features',maxDepth=5)\n",
        "gbt5 = GBTClassifier(labelCol='label', featuresCol='features',maxIter=10)\n",
        "mlp6 = MultilayerPerceptronClassifier(maxIter=50, layers=[11], blockSize=32)\n",
        "mlp7 = MultilayerPerceptronClassifier(maxIter=100, layers=[16,11], blockSize=32)\n",
        "lsvc8 = LinearSVC(maxIter=10, regParam=0.1)\n",
        "fmc9 = FMClassifier(labelCol='label', featuresCol='features', stepSize=0.001)\n",
        "cls1 = OneVsRest(classifier=lr1)\n",
        "cls2 = lr2\n",
        "cls3 = OneVsRest(classifier=dt3)\n",
        "cls4 = OneVsRest(classifier=rf4)\n",
        "cls5 = OneVsRest(classifier=gbt5)\n",
        "cls6 = mlp6\n",
        "cls7 = mlp7\n",
        "cls8 = OneVsRest(classifier=lsvc8)\n",
        "cls9 = OneVsRest(classifier=fmc9)\n",
        "cls = [cls1, cls2, cls3, cls4, cls5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYzLl-FVkYhz"
      },
      "source": [
        "models = []\n",
        "for i in range(len(cls)):\n",
        "    evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "    start_time = time()\n",
        "    model = cls[i].fit(data_train)\n",
        "    print(f\"Time elapsed for training data {i}: {time()-start_time:.2f}s\")\n",
        "    del start_time\n",
        "    start_time = time()\n",
        "    predictions = model.transform(data_test)\n",
        "    accuracy = evaluator.evaluate(predictions)\n",
        "    print(f\"Test Error for data {i} = %g\" % (1.0 - accuracy))\n",
        "    print(f\"Time elapsed for evaluating data {i}: {time()-start_time:.2f}s\")\n",
        "    del start_time\n",
        "    models.append(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4t8L2ZvrDdy"
      },
      "source": [
        "# Views Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WHhsIUGxlHK"
      },
      "source": [
        "### Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJEM_xHJxmHL"
      },
      "source": [
        "viewData = df_ALL\n",
        "required_features = [\n",
        "    'category_id',\n",
        "    'log_likes',     \n",
        "    'log_dislikes',\n",
        "    'log_comment_count'\n",
        "]\n",
        "assembler = VectorAssembler(inputCols=required_features, outputCol='features')\n",
        "start_time = time()\n",
        "data_feature = assembler.transform(viewData)\n",
        "data_feature = data_feature.select(col('log_views').alias('label'),data_feature['features'])\n",
        "print(f\"Time elapsed for featurizing data: {time()-start_time:.2f}s\")\n",
        "del start_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO6lseThxpdu",
        "outputId": "3f484f3f-114f-4120-ba8b-74c61cfbe7b9"
      },
      "source": [
        "## Data_split\n",
        "data_train, data_test = data_feature.randomSplit([0.8, 0.2])\n",
        "data_train.cache()\n",
        "data_test.cache()\n",
        "start_time = time()\n",
        "data_train.collect()\n",
        "data_test.collect()\n",
        "print(f\"Time elapsed for collecting data: {time()-start_time:.2f}s\")\n",
        "del start_time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time elapsed for collecting data: 25.66s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QPan1hlzW3v"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RWxWlA6rHld"
      },
      "source": [
        "from pyspark.ml.regression import LinearRegression, GeneralizedLinearRegression, DecisionTreeRegressor, RandomForestRegressor, GBTRegressor\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.feature import VectorIndexer\n",
        "from pyspark.ml import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYW7aeksuTfU"
      },
      "source": [
        "reg1 = LinearRegression(maxIter=100, regParam=0.3, elasticNetParam=0.8)\n",
        "reg2 = GeneralizedLinearRegression(family=\"gaussian\", link=\"identity\", maxIter=100, regParam=0.3)\n",
        "\n",
        "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=40).fit(data_feature)\n",
        "dt = DecisionTreeRegressor(featuresCol=\"indexedFeatures\")\n",
        "reg3 = Pipeline(stages=[featureIndexer, dt])\n",
        "\n",
        "rf = RandomForestRegressor(featuresCol=\"indexedFeatures\") \n",
        "reg4 = Pipeline(stages=[featureIndexer, rf])\n",
        "\n",
        "gbt = GBTRegressor(featuresCol=\"indexedFeatures\", maxIter=50)\n",
        "reg5 = Pipeline(stages=[featureIndexer, gbt])\n",
        "\n",
        "regs = [reg1, reg2, reg3, reg4, reg5]\n",
        "names = ['Linear Regression', 'Generalized Linear Regression', \n",
        "         'Decision Tree Regressor', 'Random Forest Regressor',\n",
        "         'GBT Regressor']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxME0xLeu93E",
        "outputId": "4a6ce893-67da-4e1e-d2af-e5a1dd8ba13c"
      },
      "source": [
        "models = []\n",
        "acc_list = []\n",
        "for i in range(len(regs)):\n",
        "    evaluator = RegressionEvaluator(metricName='r2')\n",
        "    start_time = time()\n",
        "    model = regs[i].fit(data_train)\n",
        "    print(f\"Time elapsed for training {names[i]}: {time()-start_time:.2f}s\")\n",
        "    del start_time\n",
        "    start_time = time()\n",
        "    predictions = model.transform(data_test)\n",
        "    accuracy = evaluator.evaluate(predictions)\n",
        "    print(f\"R2 score for {names[i]} = %g\" % (accuracy))\n",
        "    print(f\"Time elapsed for evaluating {names[i]}: {time()-start_time:.2f}s\")\n",
        "    print(\"==================================================================\")\n",
        "    acc_list.append(accuracy)\n",
        "    del start_time\n",
        "    models.append(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time elapsed for training Linear Regression: 1.15s\n",
            "R2 score for Linear Regression = 0.685498\n",
            "Time elapsed for evaluating Linear Regression: 0.23s\n",
            "==================================================================\n",
            "Time elapsed for training Generalized Linear Regression: 0.46s\n",
            "R2 score for Generalized Linear Regression = 0.765101\n",
            "Time elapsed for evaluating Generalized Linear Regression: 0.30s\n",
            "==================================================================\n",
            "Time elapsed for training Decision Tree Regressor: 2.14s\n",
            "R2 score for Decision Tree Regressor = 0.828102\n",
            "Time elapsed for evaluating Decision Tree Regressor: 0.23s\n",
            "==================================================================\n",
            "Time elapsed for training Random Forest Regressor: 5.45s\n",
            "R2 score for Random Forest Regressor = 0.846993\n",
            "Time elapsed for evaluating Random Forest Regressor: 0.41s\n",
            "==================================================================\n",
            "Time elapsed for training GBT Regressor: 130.65s\n",
            "R2 score for GBT Regressor = 0.867724\n",
            "Time elapsed for evaluating GBT Regressor: 0.93s\n",
            "==================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdW2Su4gupRx"
      },
      "source": [
        "plt.scatter(names,acc_list)\r\n",
        "plt.plot(names, acc_list)\r\n",
        "plt.xticks(rotation=45)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_mj7Xn1SKc_"
      },
      "source": [
        "# Like ratio Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gVCFedzb5OF"
      },
      "source": [
        "df_ALL = df_ALL.withColumn('log_likes_ratio', f.log10((df_ALL.likes+1)/(df_ALL.views+1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4SA0QbIblrV",
        "outputId": "bb7ef8ae-f1e6-42cb-9eb1-88bbb61f1c60"
      },
      "source": [
        "viewData = df_ALL\n",
        "required_features = [\n",
        "    'category_id',\n",
        "    'log_views',     \n",
        "    'log_dislikes',\n",
        "    'log_comment_count'\n",
        "]\n",
        "assembler = VectorAssembler(inputCols=required_features, outputCol='features')\n",
        "start_time = time()\n",
        "data_feature = assembler.transform(viewData)\n",
        "data_feature = data_feature.select(col('log_likes_ratio').alias('label'),data_feature['features'])\n",
        "print(f\"Time elapsed for featurizing data: {time()-start_time:.2f}s\")\n",
        "del start_time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time elapsed for featurizing data: 0.03s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBaB0OqdcPx2",
        "outputId": "0c1af8dd-66ec-4873-d954-a1d830225147"
      },
      "source": [
        "## Data_split\n",
        "data_train, data_test = data_feature.randomSplit([0.8, 0.2])\n",
        "data_train.cache()\n",
        "data_test.cache()\n",
        "start_time = time()\n",
        "data_train.collect()\n",
        "data_test.collect()\n",
        "print(f\"Time elapsed for collecting data: {time()-start_time:.2f}s\")\n",
        "del start_time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time elapsed for collecting data: 12.70s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpS4y7dtfTBB"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hffTPPFOcXdE"
      },
      "source": [
        "from pyspark.ml.regression import LinearRegression, GeneralizedLinearRegression, DecisionTreeRegressor, RandomForestRegressor, GBTRegressor\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.feature import VectorIndexer\n",
        "from pyspark.ml import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4xf53FbcXdE"
      },
      "source": [
        "reg1 = LinearRegression(maxIter=100, regParam=0.3, elasticNetParam=0.8)\n",
        "reg2 = GeneralizedLinearRegression(family=\"gaussian\", link=\"identity\", maxIter=100, regParam=0.3)\n",
        "\n",
        "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=40).fit(data_feature)\n",
        "dt = DecisionTreeRegressor(featuresCol=\"indexedFeatures\")\n",
        "reg3 = Pipeline(stages=[featureIndexer, dt])\n",
        "\n",
        "rf = RandomForestRegressor(featuresCol=\"indexedFeatures\") \n",
        "reg4 = Pipeline(stages=[featureIndexer, rf])\n",
        "\n",
        "gbt = GBTRegressor(featuresCol=\"indexedFeatures\", maxIter=50)\n",
        "reg5 = Pipeline(stages=[featureIndexer, gbt])\n",
        "\n",
        "regs = [reg1, reg2, reg3, reg4, reg5]\n",
        "names = ['Linear Regression', 'Generalized Linear Regression', \n",
        "         'Decision Tree Regressor', 'Random Forest Regressor',\n",
        "         'GBT Regressor']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_JbkpM1cXdF",
        "outputId": "b930da25-ccfd-4134-e3a9-2f7ab0dbe989"
      },
      "source": [
        "models = []\n",
        "acc_likelist = []\n",
        "for i in range(len(regs)):\n",
        "    evaluator = RegressionEvaluator(metricName='r2')\n",
        "    start_time = time()\n",
        "    model = regs[i].fit(data_train)\n",
        "    print(f\"Time elapsed for training {names[i]}: {time()-start_time:.2f}s\")\n",
        "    del start_time\n",
        "    start_time = time()\n",
        "    predictions = model.transform(data_test)\n",
        "    accuracy = evaluator.evaluate(predictions)\n",
        "    print(f\"R2 score for {names[i]} = %g\" % (accuracy))\n",
        "    print(f\"Time elapsed for evaluating {names[i]}: {time()-start_time:.2f}s\")\n",
        "    print(\"==================================================================\")\n",
        "    acc_likelist.append(accuracy)\n",
        "    del start_time\n",
        "    models.append(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time elapsed for training Linear Regression: 0.95s\n",
            "R2 score for Linear Regression = 0.0167303\n",
            "Time elapsed for evaluating Linear Regression: 0.22s\n",
            "==================================================================\n",
            "Time elapsed for training Generalized Linear Regression: 0.40s\n",
            "R2 score for Generalized Linear Regression = 0.25456\n",
            "Time elapsed for evaluating Generalized Linear Regression: 0.25s\n",
            "==================================================================\n",
            "Time elapsed for training Decision Tree Regressor: 2.08s\n",
            "R2 score for Decision Tree Regressor = 0.56605\n",
            "Time elapsed for evaluating Decision Tree Regressor: 0.31s\n",
            "==================================================================\n",
            "Time elapsed for training Random Forest Regressor: 5.75s\n",
            "R2 score for Random Forest Regressor = 0.592959\n",
            "Time elapsed for evaluating Random Forest Regressor: 0.36s\n",
            "==================================================================\n",
            "Time elapsed for training GBT Regressor: 55.89s\n",
            "R2 score for GBT Regressor = 0.741326\n",
            "Time elapsed for evaluating GBT Regressor: 0.78s\n",
            "==================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phob7o1Nu7BN"
      },
      "source": [
        "plt.scatter(names,acc_likelist)\r\n",
        "plt.plot(names, acc_likelist)\r\n",
        "plt.xticks(rotation=45)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}